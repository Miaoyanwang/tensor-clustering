\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cong2015tensor,zhou2013tensor}
\citation{nickel2011three,socher2013reasoning}
\citation{tang2013tensor,liu2013tensor}
\citation{wang2017three,hore2016tensor}
\citation{wang2017three}
\citation{nickel2011three}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{10}\selectfont  \abovedisplayskip 6\p@ plus1.5\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayskip \abovedisplayskip \belowdisplayshortskip 3\p@ plus2\p@ minus2\p@ Examples of tensor block model (TBM). (a) Our TBM method is used for multiway clustering and for revealing the underlying checkerbox structure in a noisy tensor. (b) The sparse TBM method is used for detecting sub-tensors of elevated means. \relax }}{1}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1}{{1}{1}{\small Examples of tensor block model (TBM). (a) Our TBM method is used for multiway clustering and for revealing the underlying checkerbox structure in a noisy tensor. (b) The sparse TBM method is used for detecting sub-tensors of elevated means. \relax }{figure.caption.2}{}}
\citation{hitchcock1927expression}
\citation{tucker1966some}
\citation{tan2014sparse,kolda2008scalable,wang2015multi}
\citation{kolda2008scalable,wang2015multi,hore2016tensor}
\citation{jegelka2009approximation,kolda2008scalable}
\citation{chi2018provable}
\citation{kolda2009tensor}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Tensor block model}{2}{section.3}}
\newlabel{eq:model}{{1}{2}{Tensor block model}{equation.3.1}{}}
\citation{madeira2004biclustering}
\citation{jegelka2009approximation,wang2017three,chi2018provable}
\citation{abbe2017community,gao2018minimax}
\citation{darton1980rotation,abdi2003factor}
\citation{zhang2018tensor,kolda2009tensor}
\citation{darton1980rotation,abdi2003factor}
\MT@newlabel{eq:model}
\newlabel{eq:Tucker}{{2}{3}{Tensor block model}{equation.3.2}{}}
\MT@newlabel{eq:Tucker}
\newlabel{eq:noise}{{3}{3}{Tensor block model}{equation.3.3}{}}
\MT@newlabel{eq:noise}
\MT@newlabel{eq:model}
\MT@newlabel{eq:model}
\newlabel{ass:core}{{1}{3}{Irreducible core}{ass.1}{}}
\newlabel{prop:factors}{{1}{3}{Identifiability}{prop.1}{}}
\MT@newlabel{eq:model}
\citation{zhang2018tensor}
\citation{chi2018provable}
\citation{gao2016optimal,gao2018minimax}
\citation{gao2018minimax}
\MT@newlabel{eq:model}
\newlabel{eq:estimate}{{4}{4}{Tensor block model}{equation.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Statistical convergence}{4}{section.4}}
\newlabel{sec:theory}{{4}{4}{Statistical convergence}{section.4}{}}
\MT@newlabel{eq:estimate}
\newlabel{eq:MSE}{{4}{4}{Statistical convergence}{section.4}{}}
\newlabel{thm:mse}{{1}{4}{Convergence rate of MSE}{theorem.1}{}}
\MT@newlabel{eq:model}
\newlabel{eq:bound}{{5}{4}{Convergence rate of MSE}{equation.4.5}{}}
\MT@newlabel{eq:noise}
\MT@newlabel{eq:bound}
\MT@newlabel{eq:bound}
\MT@newlabel{eq:bound}
\newlabel{eq:intuition}{{6}{4}{Statistical convergence}{equation.4.6}{}}
\newlabel{eq:MCR}{{4}{5}{Statistical convergence}{equation.4.6}{}}
\newlabel{thm:mcr}{{2}{5}{Convergence rate of MCR}{theorem.2}{}}
\MT@newlabel{eq:estimate}
\newlabel{eq:mcrbound}{{7}{5}{Convergence rate of MCR}{equation.4.7}{}}
\MT@newlabel{eq:mcrbound}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces {\color {blue}\uwave  {Summary of the comparison among different tensor clustering methods when $d_1=...=d_K=d, R_1=...=R_K=R$.}}\relax }}{5}{table.caption.3}}
\newlabel{tab:addcom}{{1}{5}{\DIFaddFL {Summary of the comparison among different tensor clustering methods when $d_1=...=d_K=d, R_1=...=R_K=R$.}\relax }{table.caption.3}{}}
\citation{anandkumar2014tensor,wang2017tensor,zhang2018tensor}
\citation{aloise2009np,zhou2013tensor}
\citation{zhou2013tensor}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical implementation}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Alternating optimization}{6}{subsection.5.1}}
\MT@newlabel{eq:estimate}
\MT@newlabel{eq:estimate}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Multiway clustering based on tensor block models\relax }}{6}{algorithm.1}}
\newlabel{alg:B}{{1}{6}{Multiway clustering based on tensor block models\relax }{algorithm.1}{}}
\newlabel{eq:ols}{{8}{6}{Multiway clustering based on tensor block models\relax }{equation.5.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Tuning parameter selection}{6}{subsection.5.2}}
\newlabel{sec:tuning}{{5.2}{6}{Tuning parameter selection}{subsection.5.2}{}}
\newlabel{eq:BIC}{{9}{6}{Tuning parameter selection}{equation.5.9}{}}
\MT@newlabel{eq:intuition}
\@writefile{toc}{\contentsline {section}{\numberline {6}Extension to sparse estimation}{7}{section.6}}
\MT@newlabel{eq:estimate}
\MT@newlabel{eq:ols}
\newlabel{eq:lasso}{{6}{7}{Extension to sparse estimation}{section.6}{}}
\MT@newlabel{eq:ols}
\MT@newlabel{eq:BIC}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experiments}{7}{section.7}}
\newlabel{sec:simulation}{{7}{7}{Experiments}{section.7}{}}
\MT@newlabel{eq:model}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Finite-sample performance}{7}{subsection.7.1}}
\citation{chi2018provable,hore2016tensor,kolda2008scalable}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{10}\selectfont  \abovedisplayskip 6\p@ plus1.5\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayskip \abovedisplayskip \belowdisplayshortskip 3\p@ plus2\p@ minus2\p@ Estimation error for block tensors with Gaussian noise. Each curve corresponds to a fixed clustering size $\bm  {R}$. (a) Average RMSE against {\color {red}\sout  {$d_1$}}{\color {blue}\uwave  {rescaled sample size $N_1=\sqrt  {d_2d_3/\qopname  \relax o{log}R_1}$ when tensor is of 3-order}}. (b) Average RMSE against rescaled sample size {\color {red}\sout  {$N=\sqrt  {d_2d_3/\qopname  \relax o{log}R_1}$}}{\color {blue}\uwave  {$N_2=\sqrt  {d_2d_3d_4/\qopname  \relax o{log}R_1}$ when tensor is of 4-order}}. \relax }}{8}{figure.caption.4}}
\newlabel{fig:RMSE}{{2}{8}{\small Estimation error for block tensors with Gaussian noise. Each curve corresponds to a fixed clustering size $\mR $. (a) Average RMSE against \DIFdelbeginFL \DIFdelFL {$d_1$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {rescaled sample size $N_1=\sqrt {d_2d_3/\log R_1}$ when tensor is of 3-order}\DIFaddendFL . (b) Average RMSE against rescaled sample size \DIFdelbeginFL \DIFdelFL {$N=\sqrt {d_2d_3/\log R_1}$}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {$N_2=\sqrt {d_2d_3d_4/\log R_1}$ when tensor is of 4-order}\DIFaddendFL . \relax }{figure.caption.4}{}}
\MT@newlabel{eq:BIC}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Comparison with alternative methods}{8}{subsection.7.2}}
\citation{wang2017three}
\citation{o2015reference}
\citation{o2015reference}
\citation{nickel2011three}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{10}\selectfont  \abovedisplayskip 6\p@ plus1.5\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayskip \abovedisplayskip \belowdisplayshortskip 3\p@ plus2\p@ minus2\p@ Performance comparison in terms of RMSE and CER. (a) Estimation error against noise for tensors of dimension $(40,40,40)$. (b) Clustering error against noise for tensors of dimension $(40,40,40)$. (c) Clustering error against noise for tensors of dimension $(40,50,60)$.\relax }}{9}{figure.caption.5}}
\newlabel{fig4}{{3}{9}{\small Performance comparison in terms of RMSE and CER. (a) Estimation error against noise for tensors of dimension $(40,40,40)$. (b) Clustering error against noise for tensors of dimension $(40,40,40)$. (c) Clustering error against noise for tensors of dimension $(40,50,60)$.\relax }{figure.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{10}\selectfont  \abovedisplayskip 6\p@ plus1.5\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayskip \abovedisplayskip \belowdisplayshortskip 3\p@ plus2\p@ minus2\p@ Sparse TBM for estimating tensors of dimension $\bm  {d}=(40,40,40)$. The reported $\mathaccentV {bar}016\lambda $ is the mean of $\lambda $ selected across 50 simulations using proposed BIC criterion. Number in bold indicates {\color {red}\sout  {no significant difference between }}the estimate {\color {red}\sout  {and }}{\color {blue}\uwave  {is within twice }}the {\color {blue}\uwave  {standard deviation away from the }}ground truth{\color {red}\sout  {, based on a $z$-test with a level 0.05}}.\relax }}{9}{table.caption.6}}
\newlabel{t5}{{2}{9}{\small Sparse TBM for estimating tensors of dimension $\md =(40,40,40)$. The reported $\bar \lambda $ is the mean of $\lambda $ selected across 50 simulations using proposed BIC criterion. Number in bold indicates \DIFdelbeginFL \DIFdelFL {no significant difference between }\DIFdelendFL the estimate \DIFdelbeginFL \DIFdelFL {and }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {is within twice }\DIFaddendFL the \DIFaddbeginFL \DIFaddFL {standard deviation away from the }\DIFaddendFL ground truth\DIFdelbeginFL \DIFdelFL {, based on a $z$-test with a level 0.05}\DIFdelendFL .\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Real data analysis}{9}{subsection.7.3}}
\bibstyle{unsrt}
\bibdata{tensor_wang}
\bibcite{cong2015tensor}{{1}{}{{}}{{}}}
\bibcite{zhou2013tensor}{{2}{}{{}}{{}}}
\bibcite{nickel2011three}{{3}{}{{}}{{}}}
\bibcite{socher2013reasoning}{{4}{}{{}}{{}}}
\bibcite{tang2013tensor}{{5}{}{{}}{{}}}
\bibcite{liu2013tensor}{{6}{}{{}}{{}}}
\bibcite{wang2017three}{{7}{}{{}}{{}}}
\bibcite{hore2016tensor}{{8}{}{{}}{{}}}
\bibcite{hitchcock1927expression}{{9}{}{{}}{{}}}
\bibcite{tucker1966some}{{10}{}{{}}{{}}}
\bibcite{tan2014sparse}{{11}{}{{}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces {\color {blue}\uwave  {Comparison of goodness-of-fit in the }}\emph  {{\color {blue}\uwave  {Brain}}} {\color {blue}\uwave  {expression and }}\emph  {{\color {blue}\uwave  {Nations}}} {\color {blue}\uwave  {datasets.}}\relax }}{10}{table.caption.7}}
\newlabel{tab:add}{{3}{10}{\DIFaddFL {Comparison of goodness-of-fit in the }\emph {\DIFaddFL {Brain}} \DIFaddFL {expression and }\emph {\DIFaddFL {Nations}} \DIFaddFL {datasets.}\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{10}{section.8}}
\bibcite{kolda2008scalable}{{12}{}{{}}{{}}}
\bibcite{wang2015multi}{{13}{}{{}}{{}}}
\bibcite{jegelka2009approximation}{{14}{}{{}}{{}}}
\bibcite{chi2018provable}{{15}{}{{}}{{}}}
\bibcite{kolda2009tensor}{{16}{}{{}}{{}}}
\bibcite{madeira2004biclustering}{{17}{}{{}}{{}}}
\bibcite{abbe2017community}{{18}{}{{}}{{}}}
\bibcite{gao2018minimax}{{19}{}{{}}{{}}}
\bibcite{darton1980rotation}{{20}{}{{}}{{}}}
\bibcite{abdi2003factor}{{21}{}{{}}{{}}}
\bibcite{zhang2018tensor}{{22}{}{{}}{{}}}
\bibcite{gao2016optimal}{{23}{}{{}}{{}}}
\bibcite{anandkumar2014tensor}{{24}{}{{}}{{}}}
\bibcite{wang2017tensor}{{25}{}{{}}{{}}}
\bibcite{aloise2009np}{{26}{}{{}}{{}}}
\bibcite{o2015reference}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
