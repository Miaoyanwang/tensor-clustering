\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sun2017store}
\citation{zhou2013tensor}
\citation{wu2017generalized}
\citation{baldin2018optimal}
\citation{hoff2005bilinear}
\citation{zhang2018network}
\citation{wu2017generalized}
\citation{de2000multilinear}
\citation{kolda2009tensor}
\citation{zhang2018tensor}
\citation{zhou2013tensor}
\citation{chen2019non}
\citation{rabusseau2016low}
\citation{li2017parsimonious}
\citation{hoff2005bilinear}
\citation{wu2017generalized}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{kolda2009tensor}
\citation{wang2017operator}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of tensor response regression model with covariates on multiple modes. (a) Network population model. (b) Spatial-temporal growth model. \relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro1}{{1}{2}{Examples of tensor response regression model with covariates on multiple modes. (a) Network population model. (b) Spatial-temporal growth model. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Motivation and model}{2}{section.3}}
\newlabel{sec:model}{{3}{2}{Motivation and model}{section.3}{}}
\newlabel{eq:tensormodel}{{1}{2}{Motivation and model}{equation.3.1}{}}
\citation{gabriel1998generalised}
\citation{potthoff1964generalized}
\citation{srivastava2008models}
\citation{rabusseau2016low}
\citation{zhang2018network}
\citation{hoff2005bilinear}
\newlabel{eq:time}{{2}{3}{Spatio-temporal growth model}{equation.3.2}{}}
\MT@newlabel{eq:time}
\newlabel{eq:network}{{3}{3}{Network population model}{equation.3.3}{}}
\MT@newlabel{eq:network}
\MT@newlabel{eq:network}
\newlabel{eq:edge}{{4}{3}{Dyadic data with node attributes}{equation.3.4}{}}
\MT@newlabel{eq:tensormodel}
\citation{hitchcock1927expression}
\citation{oseledets2011tensor}
\MT@newlabel{eq:edge}
\MT@newlabel{eq:tensormodel}
\newlabel{eq:rank}{{3}{4}{Motivation and model}{equation.3.4}{}}
\newlabel{eq:tensormodel}{{5}{4}{Motivation and model}{equation.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Rank-constrained likelihood-based estimation}{4}{section.4}}
\MT@newlabel{eq:tensormodel}
\MT@newlabel{eq:tensormodel}
\citation{mccullagh1989generalized}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Canonical links for common distributions.\relax }}{5}{table.caption.2}}
\newlabel{table:link}{{1}{5}{Canonical links for common distributions.\relax }{table.caption.2}{}}
\newlabel{eq:MLE}{{6}{5}{Rank-constrained likelihood-based estimation}{equation.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Statistical properties}{5}{subsection.4.1}}
\newlabel{ass}{{1}{5}{}{assumption.1}{}}
\newlabel{thm:main}{{4.1}{6}{Statistical convergence}{thm.4.1}{}}
\MT@newlabel{eq:tensormodel}
\newlabel{eq:bound}{{7}{6}{Statistical convergence}{equation.4.7}{}}
\MT@newlabel{eq:bound}
\MT@newlabel{eq:bound}
\newlabel{thm:KL}{{4.2}{6}{Prediction error}{thm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical implementation}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Alternating optimization}{6}{subsection.5.1}}
\MT@newlabel{eq:MLE}
\MT@newlabel{eq:MLE}
\newlabel{eq:tucker}{{8}{7}{Alternating optimization}{equation.5.8}{}}
\MT@newlabel{eq:MLE}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Rank selection}{7}{subsection.5.2}}
\newlabel{sec:tuning}{{5.2}{7}{Rank selection}{subsection.5.2}{}}
\citation{robinson2015dynamic}
\citation{abbe2017community}
\citation{zeng2019multiway}
\newlabel{eq:BIC}{{9}{8}{Rank selection}{equation.5.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Simulation}{8}{section.6}}
\newlabel{sec:simulation}{{6}{8}{Simulation}{section.6}{}}
\MT@newlabel{eq:tucker}
\MT@newlabel{eq:BIC}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Rank selection via BIC. Bold number indicates no significant difference between the estimate and the ground truth, based on a $z$-test with a level 0.05.\relax }}{9}{table.caption.4}}
\newlabel{tab:rank}{{2}{9}{Rank selection via BIC. Bold number indicates no significant difference between the estimate and the ground truth, based on a $z$-test with a level 0.05.\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Estimation error against effective sample size. The three panels depict the MSE when the response tensors are generated form (a) Gaussian (b) Poisson and (c) Bernoulli models. The dashed curves correspond to $\mathcal  {O}({1/d^2})$.\relax }}{9}{figure.caption.5}}
\newlabel{fig:dim}{{2}{9}{Estimation error against effective sample size. The three panels depict the MSE when the response tensors are generated form (a) Gaussian (b) Poisson and (c) Bernoulli models. The dashed curves correspond to $\tO ({1/d^2})$.\relax }{figure.caption.5}{}}
\citation{HCP}
\citation{desikan2006automated}
\citation{xia2013brainnet}
\citation{ingalhalikar2014sex}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Performance comparison when the networks have block structure. The three panels depict the MSE when the response tensors are generated form (a) Gaussian (b) Poisson and (c) Bernoulli models. The $x$-axis represents the number of blocks in the networks. \relax }}{10}{figure.caption.6}}
\newlabel{fig:glm}{{3}{10}{Performance comparison when the networks have block structure. The three panels depict the MSE when the response tensors are generated form (a) Gaussian (b) Poisson and (c) Bernoulli models. The $x$-axis represents the number of blocks in the networks. \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Data analysis}{10}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Human Connectome Project (HCP)}{10}{subsection.7.1}}
\citation{nickel2011three}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Top edges with large effects. Red edges represent relatively strong connections and blue edges represent relatively weak connections. (a) Global effect; (b) Female effect; (c) Age 22-25; (d) Age 31+.\relax }}{11}{figure.caption.7}}
\newlabel{fig:brain}{{4}{11}{Top edges with large effects. Red edges represent relatively strong connections and blue edges represent relatively weak connections. (a) Global effect; (b) Female effect; (c) Age 22-25; (d) Age 31+.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Nations data}{11}{subsection.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Effect estimation in the \emph  {Nations} data. Panels (a)-(d) represent the estimated effects of country-level attributes towards the connection probability, for relations \emph  {warnning}, \emph  {economicaid},\emph  {intergovorg}, and \emph  {commonblock}, respectively. \relax }}{12}{figure.caption.8}}
\newlabel{fig:est}{{5}{12}{Effect estimation in the \emph {Nations} data. Panels (a)-(d) represent the estimated effects of country-level attributes towards the connection probability, for relations \emph {warnning}, \emph {economicaid},\emph {intergovorg}, and \emph {commonblock}, respectively. \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusions}{12}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs}{12}{appendix.A}}
\citation{wang2018learning}
\citation{wang2017operator}
\citation{wang2018learning}
\citation{tomioka2014spectral}
\newlabel{bound}{{10}{13}{Proofs}{equation.A.10}{}}
\MT@newlabel{bound}
\newlabel{eq:bound2}{{11}{13}{Proofs}{equation.A.11}{}}
\MT@newlabel{eq:bound2}
\newlabel{eq:logbefore}{{A}{13}{Proofs}{equation.A.11}{}}
\MT@newlabel{eq:log}
\newlabel{eq:log}{{12}{13}{Proofs}{equation.A.12}{}}
\MT@newlabel{eq:log}
\newlabel{eq:logB}{{A}{13}{Proofs}{equation.A.12}{}}
\MT@newlabel{eq:log}
\newlabel{upperbound}{{13}{14}{Proofs}{equation.A.13}{}}
\MT@newlabel{upperbound}
\newlabel{eq:1}{{14}{14}{Proofs}{equation.A.14}{}}
\MT@newlabel{eq:1}
\newlabel{prop:sub}{{1}{14}{sub-Gaussian tensors}{prop.1}{}}
\citation{fan2019generalized}
\citation{baldin2018optimal}
\newlabel{prop}{{2}{15}{sub-Gaussian residuals}{prop.2}{}}
\MT@newlabel{eq:log}
\@writefile{toc}{\contentsline {section}{\numberline {B}Time complexity}{15}{appendix.B}}
\bibstyle{unsrt}
\bibdata{tensor_wang}
\bibcite{sun2017store}{1}
\bibcite{zhou2013tensor}{2}
\bibcite{wu2017generalized}{3}
\bibcite{baldin2018optimal}{4}
\@writefile{toc}{\contentsline {section}{\numberline {C}Additional results for real data analysis}{16}{appendix.C}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}HCP data analysis}{16}{subsection.C.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Nations data analysis}{16}{subsection.C.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces $K$-means clustering of relations based on factor matrix in the coefficient tensor.\relax }}{16}{table.caption.10}}
\newlabel{tab:s1}{{3}{16}{$K$-means clustering of relations based on factor matrix in the coefficient tensor.\relax }{table.caption.10}{}}
\bibcite{hoff2005bilinear}{5}
\bibcite{zhang2018network}{6}
\bibcite{de2000multilinear}{7}
\bibcite{kolda2009tensor}{8}
\bibcite{zhang2018tensor}{9}
\bibcite{chen2019non}{10}
\bibcite{rabusseau2016low}{11}
\bibcite{li2017parsimonious}{12}
\bibcite{wang2017operator}{13}
\bibcite{gabriel1998generalised}{14}
\bibcite{potthoff1964generalized}{15}
\bibcite{srivastava2008models}{16}
\bibcite{hitchcock1927expression}{17}
\bibcite{oseledets2011tensor}{18}
\bibcite{mccullagh1989generalized}{19}
\bibcite{robinson2015dynamic}{20}
\bibcite{abbe2017community}{21}
\bibcite{zeng2019multiway}{22}
\bibcite{HCP}{23}
\bibcite{desikan2006automated}{24}
\bibcite{xia2013brainnet}{25}
\bibcite{ingalhalikar2014sex}{26}
\bibcite{nickel2011three}{27}
\bibcite{wang2018learning}{28}
\bibcite{tomioka2014spectral}{29}
\bibcite{fan2019generalized}{30}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison of coefficient estimation in the HCP data.\relax }}{19}{figure.caption.9}}
\newlabel{fig:s1}{{6}{19}{Comparison of coefficient estimation in the HCP data.\relax }{figure.caption.9}{}}
